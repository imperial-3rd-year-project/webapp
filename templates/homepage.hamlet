<div .masthead>
    <div .container>
        <div .row>
            <h1 .header>
                Grenade
            <h2>
                Functional Neural Networks in Haskell

<div .container>
    <div .bs-docs-section>
        <div .row>
            <div .col-lg-12>
                <div .page-header>
                    <h1>What is Grenade?
                    <p>
                        Grenade brings composable, statically typed neural networks to Haskell. 
                        In particular, this means that networks are defined as types, with shapes 
                        checked at compile time, and networks can be used as layers in other networks.

                        For example, we can define a simple network as follows:
                    
                    <pre>
                        <code .language-haskell>
                            type FL i o = Network '[ FullyConnected i o, Logit ] '[ 'D1 i, 'D1 o, 'D1 o]
                    <p>
                        and use it within a more complex network:

                    <pre>
                        <code .language-haskell>
                            type Net = Network '[ FL 288 80, FL 80 10 ] '[ D1 288, 'D1 80, 'D1 10 ]

                    <h1> 
                        Why have types?
                    <p> 
                        Static typing in this manner can have a multitude of advantages for
                        the developer. Consider

                        For example, compare the following snippets of code used to define a 
                        network, the first written with Grenade and the second with Keras.
                    
                    <pre>
                        <code .language-haskell>
                            \type MyNetwork = Network
                            \   '[ Convolution 1 32 4 4 1 1, Relu
                            \    , Pooling 2 2 2 2
                            \    , Convolution 1 16 4 4 1 1, Relu
                            \    , Pooling 2 2 2 2
                            \    , Reshape
                            \    , FullyConnected 2704 10,   Relu
                            \    , FullyConnected 10 1,      Logit ]
                            \   '[ 'D2 64 64                   -- Input
                            \    , 'D3 61 61 32, 'D3 61 61 32  -- Convolution, Relu
                            \    , 'D3 30 30 32                -- Pooling
                            \    , 'D3 27 27 16, 'D3 27 27 16  -- Convolution, Relu
                            \    , 'D3 26 26 16                -- Pooling
                            \    , 'D1 10816,                  -- Reshape
                            \    , 'D1 10,       'D1 10        -- FullyConnected, Relu
                            \    , 'D1 1,        'D1 1 ]       -- FullyConnected, Logit
                    <pre>
                        <code .language-python>
                            \visible = Input(shape=(64,64,1))
                            \conv1 = Conv2D(32, kernel_size=4, activation='relu')(visible)
                            \pool1 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(conv1)
                            \conv2 = Conv2D(16, kernel_size=4, activation='relu')(pool1)
                            \pool2 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(conv2)
                            \flat = Flatten()(pool2)
                            \hidden1 = Dense(10, activation='relu')(flat)
                            \output = Dense(1, activation='sigmoid')(hidden1)
                            \model = Model(inputs=visible, outputs=output)
                    
                    <p>
                        Unfortunately, there is an issue here: in both networks, we have
                        incorrectly set the <code>strides</code> parameter of the second pooling layer to
                        <code>(2, 2)</code>, when in fact it should have been set to <code>(1, 1)</code>! Such an
                        error could occur, for example, if the programmer copy-pasted the
                        definition of the first layer and forgot to change the parameter, and
                        indeed in Python such an error will never be flagged to the user as
                        we have created a fully acceptable, albeit undesired, network. On the
                        other hand, running the network written in Grenade will return an error
                        at <emph>compile time</emph>: the layers we have used do not transform the shapes
                        as specified. Notice that with <code>strides</code> set to <code>(2, 2)</code>, 
                        the output shape of the layer would actually be <code>'D3 13 13 16</code>, 
                        but here we have asserted it to be <code>'D3 26 26 16</code>.


